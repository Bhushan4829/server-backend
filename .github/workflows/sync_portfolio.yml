name: Sync Portfolio Data

on:
  schedule:
    - cron: '0 */8 * * *'  # Every 8 hours
  workflow_dispatch:  # Manual trigger
  push:
    branches:
      - main

jobs:
  sync-data:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL }}  # Now using consistent name
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      PINECONE_API_KEY: ${{ secrets.PINECONE_API_KEY }}
      PINECONE_INDEX: ${{ secrets.PINECONE_INDEX }}
      GSHEET_URL: ${{ secrets.GSHEET_URL }}  # For Excel extraction

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install psycopg2-binary pinecone-client openai python-dotenv pandas sqlalchemy gspread

    - name: Extract Excel to Postgres
      run: python extracting_data_for_portfolio.py
      env:
        DATABASE_URL: ${{ env.DATABASE_URL }}  # Inherits from job env
        GSHEET_URL: ${{ env.GSHEET_URL }}

    - name: Sync Postgres to Pinecone
      run: python sync_postgres_pinecone.py
      env:
        DATABASE_URL: ${{ env.DATABASE_URL }}
        OPENAI_API_KEY: ${{ env.OPENAI_API_KEY }}
        PINECONE_API_KEY: ${{ env.PINECONE_API_KEY }}
        PINECONE_INDEX: ${{ env.PINECONE_INDEX }}

    - name: Upload logs if failed
      if: failure()
      uses: actions/upload-artifact@v3
      with:
        name: sync-logs
        path: |
          *.log
          *.error